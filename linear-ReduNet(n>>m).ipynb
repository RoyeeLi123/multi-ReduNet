{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-confirmation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is used for GPU\n",
    "# train_set is in R^{m_train x d} and test_set is in R^{m_test x d} , m_train is the size of traing set, m_test is the size of test set, d is dimension of features.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# data setup\n",
    "X_train=train_set\n",
    "y_train=train_label\n",
    "X_test=test_set\n",
    "y_test=test_label\n",
    "num_classes = \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import cupy as cp\n",
    "\n",
    "layers=10\n",
    "eta=0.5\n",
    "eps=0.1\n",
    "\n",
    "\n",
    "def forward(F, Z, y):\n",
    "    gam=compute_gam(y)\n",
    "    m,d=Z.shape\n",
    "    #F=np.eye(d) #初始化矩阵为单位矩阵\n",
    "    c=d / (m * eps)\n",
    "    preE=cp.linalg.inv(cp.eye(m)+c*Z@F.T@F@Z.T)\n",
    "    E=c* (cp.eye(d)-c*F@Z.T@preE@Z@F.T)\n",
    "    expd=E @ F @ Z.T @ Z\n",
    "    for j in range(num_classes):\n",
    "        Z_j=Z[y==j]\n",
    "        m_j=Z_j.shape[0]\n",
    "        c_j=d / (m_j * eps)\n",
    "        preC=cp.linalg.inv(cp.eye(m_j)+c_j*Z_j@F.T@F@Z_j.T)\n",
    "        Cj=c_j*(cp.eye(d)-c_j*F@Z_j.T@preC@Z_j@F.T)\n",
    "        if j==0:\n",
    "            clus=gam[j]* Cj @ F @ Z_j.T @ Z_j\n",
    "        else:\n",
    "            clus=clus+ gam[j]* Cj @ F @ Z_j.T @ Z_j\n",
    "    F=F+eta*(expd-clus)\n",
    "    return F,Z,y\n",
    "\n",
    "def compute_gam( y):\n",
    "    m_j = [(y==j).nonzero()[0].size for j in range(num_classes)]\n",
    "    gam = np.array(m_j) / y.size\n",
    "    return gam\n",
    "\n",
    "def compute_loss(F, Z, y):\n",
    "    gam=compute_gam(y)\n",
    "    m, d = Z.shape\n",
    "    I = np.eye(d)\n",
    "    c = d / (m * eps)\n",
    "    logdet = cp.linalg.slogdet(I + c * F@Z.T @ Z @F.T)[1]\n",
    "    loss_expd = logdet / 2.\n",
    "\n",
    "    loss_comp = 0.\n",
    "    for j in np.arange(num_classes):\n",
    "        idx = (y == int(j))\n",
    "        Z_j = Z[idx, :]\n",
    "        m_j = Z_j.shape[0]\n",
    "        if m_j == 0:\n",
    "            continue\n",
    "        c_j = d / (m_j * eps)\n",
    "        logdet_j = cp.linalg.slogdet(I + c_j *F@ Z_j.T @ Z_j@F.T)[1]\n",
    "        loss_comp += gam[j] * logdet_j / 2.\n",
    "    return loss_expd - loss_comp, loss_expd, loss_comp\n",
    "\n",
    "def normalize(X, p=2):\n",
    "    axes = tuple(np.arange(1, len(X.shape)).tolist())\n",
    "    norm = np.linalg.norm(X.reshape(X.shape[0], -1), axis=1, ord=p)\n",
    "    norm = np.clip(norm, 1e-8, np.inf)\n",
    "    return X / np.expand_dims(norm, axes)\n",
    "\n",
    "#layers=10\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "F=cp.eye(X_train.shape[1])\n",
    "\n",
    "Z=X_train\n",
    "y=y_train\n",
    "start_time=time.time()\n",
    "for i in range(layers):\n",
    "    F,Z,y=forward(F,Z,y)\n",
    "    #loss_total,loss_expd,loss_comp=compute_loss(F,Z,y)\n",
    "    #print(f\"layer: {i} | loss_total: {loss_total:5f} | loss_expd: {loss_expd:5f} | loss_comp: {loss_comp:5f}\")\n",
    "end_time=time.time()\n",
    "\n",
    "Z_train=X_train@F.T\n",
    "Z_test=X_test@F.T\n",
    "\n",
    "\n",
    "Z_train=cp.asnumpy(Z_train)\n",
    "y_train=cp.asnumpy(y_train)\n",
    "Z_test=cp.asnumpy(Z_test)\n",
    "y_test=cp.asnumpy(y_test)\n",
    "\n",
    "Z_train=normalize(Z_train)\n",
    "Z_test=normalize(Z_test)\n",
    "\n",
    "\n",
    "##evaluate\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def svm(train_features, train_labels, test_features, test_labels):\n",
    "    svm = LinearSVC(verbose=0, random_state=10)\n",
    "    svm.fit(train_features, train_labels)\n",
    "    acc_train = svm.score(train_features, train_labels)\n",
    "    acc_test = svm.score(test_features, test_labels)\n",
    "    print(\"SVM: {}\".format(acc_test))\n",
    "    return acc_train, acc_test\n",
    "\n",
    "def knn(train_features, train_labels, test_features, test_labels, k=5):\n",
    "    \"\"\"Perform k-Nearest Neighbor classification using cosine similaristy as metric.\n",
    "    Options:\n",
    "        k (int): top k features for kNN\n",
    "\n",
    "    \"\"\"\n",
    "    sim_mat = train_features @ test_features.T\n",
    "    topk = torch.from_numpy(sim_mat).topk(k=k, dim=0)\n",
    "    topk_pred = train_labels[topk.indices]\n",
    "    test_pred = torch.tensor(topk_pred).mode(0).values.detach()\n",
    "\n",
    "    #print(\"knn\",test_pred[0])\n",
    "\n",
    "    acc = compute_accuracy(test_pred.numpy(), test_labels)\n",
    "    print(\"kNN: {}\".format(acc))\n",
    "    return acc\n",
    "\n",
    "def nearsub(train_features, train_labels, test_features, test_labels, n_comp=10):\n",
    "    \"\"\"Perform nearest subspace classification.\n",
    "\n",
    "    Options:\n",
    "        n_comp (int): number of components for PCA or SVD\n",
    "\n",
    "    \"\"\"\n",
    "    scores_svd = []\n",
    "    classes = np.unique(test_labels)\n",
    "    features_sort, _ = sort_dataset(train_features, train_labels,\n",
    "                                          classes=classes, stack=False)\n",
    "    fd = features_sort[0].shape[1]\n",
    "    if n_comp >= fd:\n",
    "        n_comp = fd - 1\n",
    "    for j in np.arange(len(classes)):\n",
    "        svd = TruncatedSVD(n_components=n_comp).fit(features_sort[j])\n",
    "        svd_subspace = svd.components_.T\n",
    "        svd_j = (np.eye(fd) - svd_subspace @ svd_subspace.T) \\\n",
    "                        @ (test_features).T\n",
    "        score_svd_j = np.linalg.norm(svd_j, ord=2, axis=0)\n",
    "        scores_svd.append(score_svd_j)\n",
    "    test_predict_svd = np.argmin(scores_svd, axis=0)\n",
    "    ###\n",
    "    #print('predict_svd',test_predict_svd[0])\n",
    "    ###\n",
    "    acc_svd = compute_accuracy(classes[test_predict_svd], test_labels)\n",
    "    print('SVD: {}'.format(acc_svd))\n",
    "    return acc_svd\n",
    "\n",
    "def nearsub_pca(train_features, train_labels, test_features, test_labels, n_comp=10):\n",
    "    \"\"\"Perform nearest subspace classification.\n",
    "\n",
    "    Options:\n",
    "        n_comp (int): number of components for PCA or SVD\n",
    "\n",
    "    \"\"\"\n",
    "    scores_pca = []\n",
    "    classes = np.unique(test_labels)\n",
    "    features_sort, _ = sort_dataset(train_features, train_labels,\n",
    "                                          classes=classes, stack=False)\n",
    "    fd = features_sort[0].shape[1]\n",
    "    if n_comp >= fd:\n",
    "        n_comp = fd - 1\n",
    "    for j in np.arange(len(classes)):\n",
    "        pca = PCA(n_components=n_comp).fit(features_sort[j])\n",
    "        pca_subspace = pca.components_.T\n",
    "        mean = np.mean(features_sort[j], axis=0)\n",
    "        pca_j = (np.eye(fd) - pca_subspace @ pca_subspace.T) \\\n",
    "                        @ (test_features - mean).T\n",
    "        score_pca_j = np.linalg.norm(pca_j, ord=2, axis=0)\n",
    "        scores_pca.append(score_pca_j)\n",
    "    test_predict_pca = np.argmin(scores_pca, axis=0)\n",
    "    acc_pca = compute_accuracy(classes[test_predict_pca], test_labels)\n",
    "    print('PCA: {}'.format(acc_pca))\n",
    "    return acc_svd\n",
    "\n",
    "def compute_accuracy(y_pred, y_true):\n",
    "    \"\"\"Compute accuracy by counting correct classification. \"\"\"\n",
    "    assert y_pred.shape == y_true.shape\n",
    "    return 1 - np.count_nonzero(y_pred - y_true) / y_true.size\n",
    "\n",
    "def baseline(train_features, train_labels, test_features, test_labels):\n",
    "    test_models = {'log_l2': SGDClassifier(loss='log', max_iter=10000, random_state=42),\n",
    "                   'SVM_linear': LinearSVC(max_iter=10000, random_state=42),\n",
    "                   'SVM_RBF': SVC(kernel='rbf', random_state=42),\n",
    "                   'DecisionTree': DecisionTreeClassifier(),\n",
    "                   'RandomForrest': RandomForestClassifier()}\n",
    "    for model_name in test_models:\n",
    "        test_model = test_models[model_name]\n",
    "        test_model.fit(train_features, train_labels)\n",
    "        score = test_model.score(test_features, test_labels)\n",
    "        print(f\"{model_name}: {score}\")\n",
    "\n",
    "def sort_dataset(data, labels, classes, stack=False):\n",
    "    \"\"\"Sort dataset based on classes.\n",
    "\n",
    "    Parameters:\n",
    "        data (np.ndarray): data array\n",
    "        labels (np.ndarray): one dimensional array of class labels\n",
    "        classes (int): number of classes\n",
    "        stack (bol): combine sorted data into one numpy array\n",
    "\n",
    "    Return:\n",
    "        sorted data (np.ndarray), sorted_labels (np.ndarray)\n",
    "\n",
    "    \"\"\"\n",
    "    if type(classes) == int:\n",
    "        classes = np.arange(classes)\n",
    "    sorted_data = []\n",
    "    sorted_labels = []\n",
    "    for c in classes:\n",
    "        idx = (labels == c)\n",
    "        data_c = data[idx]\n",
    "        labels_c = labels[idx]\n",
    "        sorted_data.append(data_c)\n",
    "        sorted_labels.append(labels_c)\n",
    "    if stack:\n",
    "        sorted_data = np.vstack(sorted_data)\n",
    "        sorted_labels = np.hstack(sorted_labels)\n",
    "    return sorted_data, sorted_labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "_, acc_svm = svm(Z_train, y_train, Z_test, y_test)\n",
    "acc_knn = knn(Z_train, y_train, Z_test, y_test, k=5)\n",
    "acc_svd = nearsub(Z_train, y_train, Z_test, y_test, n_comp=5)\n",
    "acc = {\"svm\": acc_svm, \"knn\": acc_knn, \"nearsub-svd\": acc_svd}\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Model execution time: {elapsed_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infrared-breed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
